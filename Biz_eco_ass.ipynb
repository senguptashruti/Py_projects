{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036d17db",
   "metadata": {},
   "source": [
    "# 1. Proportion of Above/Below Average Looks by Gender\n",
    "We first compute the fraction of men and women with above-average looks (indicated by abvavg=1 ) and\n",
    "below-average looks ( belavg=1 ). The Python output below shows these fractions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b4eaf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men above average (abvavg=1): 29.00%\n",
      "Men below average (belavg=1): 11.65%\n",
      "Women above average: 33.03%\n",
      "Women below average: 13.53%\n",
      "Overall above average: 30.40%\n",
      "Overall below average: 12.30%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data (adjust path if needed)\n",
    "df = pd.read_excel(\"beauty.xlsx\")\n",
    "\n",
    "# Total counts by gender\n",
    "total_men = df[df['female'] == 0].shape[0]\n",
    "total_women = df[df['female'] == 1].shape[0]\n",
    "total_people = df.shape[0]\n",
    "\n",
    "# Compute fractions for men\n",
    "male_abv_frac = df[(df['female'] == 0) & (df['abvavg'] == 1)].shape[0] / total_men\n",
    "male_bel_frac = df[(df['female'] == 0) & (df['belavg'] == 1)].shape[0] / total_men\n",
    "\n",
    "# Compute fractions for women\n",
    "female_abv_frac = df[(df['female'] == 1) & (df['abvavg'] == 1)].shape[0] / total_women\n",
    "female_bel_frac = df[(df['female'] == 1) & (df['belavg'] == 1)].shape[0] / total_women\n",
    "\n",
    "# Overall fractions\n",
    "above_frac = df[df['abvavg'] == 1].shape[0] / total_people\n",
    "below_frac = df[df['belavg'] == 1].shape[0] / total_people\n",
    "\n",
    "# Reassign for clarity in print statements\n",
    "men_abv_frac = male_abv_frac\n",
    "men_bel_frac = male_bel_frac\n",
    "women_abv_frac = female_abv_frac\n",
    "women_bel_frac = female_bel_frac\n",
    "overall_abv_frac = above_frac\n",
    "overall_bel_frac = below_frac\n",
    "\n",
    "# Display the results\n",
    "print(f\"Men above average (abvavg=1): {men_abv_frac:.2%}\")\n",
    "print(f\"Men below average (belavg=1): {men_bel_frac:.2%}\")\n",
    "print(f\"Women above average: {women_abv_frac:.2%}\")\n",
    "print(f\"Women below average: {women_bel_frac:.2%}\")\n",
    "print(f\"Overall above average: {overall_abv_frac:.2%}\")\n",
    "print(f\"Overall below average: {overall_bel_frac:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f3c2b",
   "metadata": {},
   "source": [
    "### Men: 29.0% of men are classified as above-average in looks, while 11.7% are below-average.\n",
    "### Women: 33.0% of women are above-average in looks, and 13.5% are below-average.\n",
    "- Overall: 30.4% of all individuals are above-average, whereas only 12.3% are below-average.\n",
    "- This shows that more people are rated above average than below average overall. Interestingly, women have a\n",
    "  higher fraction in both categories (above and below) than men, suggesting women are more often rated at\n",
    "  the extremes of appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba8084",
   "metadata": {},
   "source": [
    "# 2. Pooled Regression (Without Gender Interactions)\n",
    "We estimate the pooled regression model with heteroskedasticity-robust standard errors:\n",
    "ln(wage) = β0 + β1 belavg + β2 abvavg + β3 female + β4 educ + β5 exper + β6 exper2 + u.\n",
    "- The Python code below fits this model and prints the robust-summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2072263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.5375      0.105      5.129      0.000       0.332       0.743\n",
      "belavg            -0.1694      0.053     -3.171      0.002      -0.274      -0.065\n",
      "abvavg            -0.0391      0.039     -0.997      0.319      -0.116       0.038\n",
      "female            -0.4968      0.161     -3.087      0.002      -0.812      -0.181\n",
      "educ               0.0610      0.007      8.551      0.000       0.047       0.075\n",
      "exper              0.0505      0.005      9.279      0.000       0.040       0.061\n",
      "expersq           -0.0008      0.000     -6.956      0.000      -0.001      -0.001\n",
      "female:belavg      0.0436      0.084      0.518      0.604      -0.121       0.209\n",
      "female:abvavg      0.0824      0.065      1.263      0.207      -0.046       0.210\n",
      "female:educ        0.0177      0.011      1.564      0.118      -0.004       0.040\n",
      "female:exper      -0.0207      0.009     -2.236      0.025      -0.039      -0.003\n",
      "female:expersq     0.0003      0.000      1.359      0.174      -0.000       0.001\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "res_interact = smf.ols('lwage ~ belavg + abvavg + female + educ + exper + expersq '\n",
    "                       '+ female:belavg + female:abvavg + female:educ + female:exper + female:expersq',\n",
    "                       data=df).fit(cov_type='HC3')\n",
    "print(res_interact.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cc1b9",
   "metadata": {},
   "source": [
    "### Interpretation of key coefficients:\n",
    "- belavg has a negative coefficient (≈–0.154, p<0.01). This indicates that, holding other factors constant, individuals rated as quite plain have substantially lower wages: about 15.4% lower wage (in log points) than average-looking individuals.\n",
    "- abvavg is essentially zero (≈–0.0066, p=0.832), implying strikingly attractive people do not earn significantly more than average-looking peers. This is somewhat surprising: one might expect a “beauty premium,” but here the effect is small and statistically insignificant.\n",
    "- female has a large negative coefficient (≈–0.453, p<0.001). This means women earn on average about 45.3% less than men (since exp(–0.453)≈0.64), ceteris paribus. This effect is both statistically and practically very large.\n",
    "- educ, exper have positive, significant coefficients (≈0.066 and 0.040 respectively), as expected: more schooling and experience increase wages. The negative expersq indicates diminishing returns to experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968107e7",
   "metadata": {},
   "source": [
    "# 3. Extended Model with Gender Interactions\n",
    "Next we add interaction terms between female and each explanatory variable to allow for gender-specific effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f500019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.5375      0.105      5.129      0.000       0.332       0.743\n",
      "belavg            -0.1694      0.053     -3.171      0.002      -0.274      -0.065\n",
      "abvavg            -0.0391      0.039     -0.997      0.319      -0.116       0.038\n",
      "female            -0.4968      0.161     -3.087      0.002      -0.812      -0.181\n",
      "educ               0.0610      0.007      8.551      0.000       0.047       0.075\n",
      "exper              0.0505      0.005      9.279      0.000       0.040       0.061\n",
      "expersq           -0.0008      0.000     -6.956      0.000      -0.001      -0.001\n",
      "female:belavg      0.0436      0.084      0.518      0.604      -0.121       0.209\n",
      "female:abvavg      0.0824      0.065      1.263      0.207      -0.046       0.210\n",
      "female:educ        0.0177      0.011      1.564      0.118      -0.004       0.040\n",
      "female:exper      -0.0207      0.009     -2.236      0.025      -0.039      -0.003\n",
      "female:expersq     0.0003      0.000      1.359      0.174      -0.000       0.001\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "res_interact = smf.ols('lwage ~ belavg + abvavg + female + educ + exper + expersq '\n",
    "                       '+ female:belavg + female:abvavg + female:educ + female:exper + female:expersq',\n",
    "                       data=df).fit(cov_type='HC3')\n",
    "print(res_interact.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75faf5eb",
   "metadata": {},
   "source": [
    "### Interpretation with interactions: The main effects (non-interacted) are now conditional on female=0 (males). For example, for men, belavg has coefficient –0.169 (worse than in the pooled model), and female (the female intercept shift) is –0.497.\n",
    "The extended model shows that the effects of attractiveness variables (belavg, abvavg) do not differ significantly by gender. The largest interaction effect is on experience: women appear to accumulate wage gains from experience more slowly than men."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e71e1",
   "metadata": {},
   "source": [
    "# 4. Joint Significance of Gender-Interactions\n",
    "We now test whether all five interaction terms (female:belavg, female:abvavg, female:educ, female:exper, female:expersq) are jointly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c273e1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic F-test: F = 3.431, p = 0.0044\n",
      "Robust F-test:  F = 3.759, p = 0.0022\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis: all interaction terms are jointly zero\n",
    "H0 = 'female:belavg = 0, female:abvavg = 0, female:educ = 0, female:exper = 0, female:expersq = 0'\n",
    "\n",
    "# OLS estimation\n",
    "res_nr = smf.ols('lwage ~ belavg + abvavg + female + educ + exper + expersq '\n",
    "                 '+ female:belavg + female:abvavg + female:educ + female:exper + female:expersq',\n",
    "                 data=df).fit()\n",
    "\n",
    "# Classic F-test and robust F-test\n",
    "f_test_nonrob = res_nr.f_test(H0)\n",
    "f_test_rob = res_nr.get_robustcov_results(cov_type='HC3').f_test(H0)\n",
    "\n",
    "\n",
    "print(f\"Classic F-test: F = {f_test_nonrob.fvalue:.3f}, p = {f_test_nonrob.pvalue:.4f}\")\n",
    "print(f\"Robust F-test:  F = {f_test_rob.fvalue:.3f}, p = {f_test_rob.pvalue:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b55cc6",
   "metadata": {},
   "source": [
    "- Both tests reject the null at conventional levels (p<0.01). This indicates that collectively the gender-interaction terms are statistically significant. The robust F (p≈0.0022) is even slightly more significant than the classic F (p≈0.0044). In practice, the inference is the same: adding all five interactions improves the fit significantly. Thus, we conclude that at least one interaction is important in explaining wages, even though some individual interaction coefficients were not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811ace6",
   "metadata": {},
   "source": [
    "# 5. Specific Test of Attractiveness Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd3649e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classic F-test (attractiveness): F = 0.851, p = 0.4273\n",
      "Robust F-test (attractiveness):  F = 0.818, p = 0.4415\n"
     ]
    }
   ],
   "source": [
    "H0_attr = 'female:belavg = 0, female:abvavg = 0'\n",
    "f_test_attr_nonrob = res_nr.f_test(H0_attr)\n",
    "f_test_attr_rob = res_nr.get_robustcov_results(cov_type='HC3').f_test(H0_attr)\n",
    "\n",
    "print(f\"Classic F-test (attractiveness): F = {f_test_attr_nonrob.fvalue:.3f}, p = {f_test_attr_nonrob.pvalue:.4f}\")\n",
    "print(f\"Robust F-test (attractiveness):  F = {f_test_attr_rob.fvalue:.3f}, p = {f_test_attr_rob.pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c88aa4",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- More individuals are rated above-average in looks than below-average (30.4% vs. 12.3%), with women slightly more likely than men to be in either extreme.\n",
    "- In the pooled model, being plain significantly lowers wages, but being strikingly attractive has no significant effect. Women earn much less than men (∼45% lower).\n",
    "- Allowing interactions shows that women may have slightly different returns to education and experience (notably, lower returns to experience), but there is no significant gender difference in the effect of looks on wages.\n",
    "- Joint tests confirm that the set of all gender-interactions is significant, but specifically the interactions on attractiveness are not. Thus, looks-related pay differences are essentially the same for men and women in this sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
